"""
This module defines constructs for the optimizer.
See optimize.py
"""

import asyncio
import os
import random
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Literal

import dspy
import pandas as pd
from gnagent.agent import GNAgent
from gnagent.config import *
from gnagent.prompts import *
from langchain_core.messages import BaseMessage

API_KEY = os.getenv("API_KEY")

REFLECTION_MODEL = GENERATIVE_MODEL


class Judge(dspy.Signature):
    question: str = dspy.InputField()
    answer: bool = dspy.OutputField()


judge = dspy.Predict(Judge)


def match_checker(
    example: dspy.Example,
    prediction: dspy.Prediction,
    trace=None,
    pred_name=None,
    pred_trace=None,
) -> int:

    logging.info(f"Example: {example}")
    logging.info(f"Prediction: {prediction}")

    query = example["query"]
    generated_answer = prediction.get("answer")

    context = f"Query: {query}\nAnswer of the AI system: {generated_answer}"

    relevance = f"{context}\nHas the answer of the AI system addressed the query?"
    relevance_score = judge(question=relevance).get("answer")

    formulation = f"{context}\nIs the answer of the AI system to the query well elaborated and detailed?"
    formulation_score = judge(question=formulation).get("answer")

    contradiction = f"{context}\nIs the answer generated by the AI system free of any contradiction?"
    contradiction_score = judge(question=contradiction).get("answer")

    irregularity = (
        f"{context}\nIs the answer generated by the AI system free of any irregularity?"
    )
    irregularity_score = judge(question=irregularity).get("answer")

    cloudiness = f"{context}\nIs there any information in the answer generated by the AI system that is superficial or of no use with respect to the query?"
    cloudiness_score = judge(question=cloudiness).get("answer")

    score = (
        relevance_score
        + formulation_score
        + contradiction_score
        + cloudiness_score
        + irregularity_score
    )
    logging.info(f"Score: {score}")

    return 1 if score >= 3 else 0


def match_checker_feedback(
    example: dspy.Example,
    prediction: dspy.Prediction,
    trace=None,
    pred_name=None,
    pred_trace=None,
) -> dspy.Prediction:

    logging.info(f"Example: {example}")
    logging.info(f"Prediction: {prediction}")

    query = example["query"]
    correct_answer = example["prompt_output"]
    correct_reasoning = example["reasoning"]
    generated_answer = prediction.get("prompt_output")

    answer_similarity = f"Correct answer: {correct_answer} \nAnswer generated by the AI system: {generated_answer}. \nDoes the answer generated by the AI system contains the correct answer?"
    similarity_score = judge(question=answer_similarity).get("answer")

    reasoning_logic = f"Query: {query} \nCorrect reasoning: {correct_reasoning} \nReasoning of the AI system: {generated_answer}. \nRegardless of the reasoning of the system being in line with the correct reasoning or not, does it seem logical in addressing the query?"
    logic_score = judge(question=reasoning_logic).get("answer")

    use = f"Query: {query} \nAnswer of the AI system: {generated_answer}. \nDoes the answer of the system of any use in addressing the query?"
    use_score = judge(question=use).get("answer")

    score = similarity_score + logic_score + use_score
    logging.info(f"Score: {score}")

    feedback = ""
    final_score = 0
    if score >= 2:
        final_score = 1
        feedback += f"Your answer or reasoning is acceptable. The correct answer is '{correct_answer}'."
    else:
        feedback += f"Sorry, neither your answer nor reasoning is acceptable. The correct answer is '{correct_answer}'."

    if correct_reasoning:
        feedback += f" Here's the full step-by-step reasoning:\n{correct_reasoning}\n\nThink about what takeaways you can learn from this solution to improve your future answers and approach to similar queries."

    return dspy.Prediction(score=final_score, feedback=feedback)
