"""
This module defines constructs for the optimizer.
See optimize.py
"""

import asyncio
import os
import random
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Literal

import dspy
import pandas as pd
from gnagent.agent import GNAgent
from gnagent.config import *
from gnagent.prompts import *
from langchain_core.messages import BaseMessage

EXAMPLE_PATH = "examples/examples.csv"


def get_dataset(split_ratio: int = 0.7, example_path: str = EXAMPLE_PATH) -> Any:
    data = pd.read_csv(example_path, nrows=30)
    data_dict = data_dicts = data[["query", "answer", "reasoning"]].to_dict(
        orient="records"
    )
    formatted = [
        dspy.Example(
            {"query": x["query"], "answer": x["answer"], "reasoning": x["reasoning"]}
        ).with_inputs("query")
        for x in data_dicts
    ]
    random.Random(2025).shuffle(formatted)
    train_set = formatted[: int(split_ratio * len(formatted))]
    eval_set = formatted[int(split_ratio * len(formatted)) :]

    # Always use 50-50 for validation and test sets
    val_set = eval_set[: int(0.5 * len(eval_set))]
    test_set = eval_set[int(0.5 * len(eval_set)) :]

    return train_set, val_set, test_set


API_KEY = os.getenv("API_KEY")

REFLECTION_MODEL = dspy.LM(
    "anthropic/claude-haiku-4-5-20251001",
    api_key=API_KEY,
    max_tokens=10_000,
    temperature=0,
    verbose=False,
)


class Judge(dspy.Signature):
    question: str = dspy.InputField()
    answer: bool = dspy.OutputField()


judge = dspy.Predict(Judge)


def match_checker(
    example: dspy.Example,
    prediction: dspy.Prediction,
    trace=None,
    pred_name=None,
    pred_trace=None,
) -> int:

    logging.info(f"Example: {example}")
    logging.info(f"Prediction: {prediction}")

    correct_answer = example["answer"]
    correct_reasoning = example["reasoning"]
    generated_answer = prediction.get("answer")
    generated_reasoning = prediction.get("reasoning")

    similarity = f"Correct answer: {correct_answer} \nAnswer generated by the AI system: {generated_answer}. \nIs the correct answer similar to the answer generated by the AI system?"
    similarity_score = judge(question=similarity).get("answer")

    reasoning = f"Correct reasoning: {correct_reasoning} \nReasoning of the AI system: {generated_reasoning}. \nIs the reasoning of the AI system any similar to the correct reasoning?"
    reasoning_score = judge(question=similarity_score).get("answer")

    score = similarity_score + reasoning_score
    logging.info(f"Score: {score}")

    return 1 if score >= 1 else 0


def match_checker_feedback(
    example: dspy.Example,
    prediction: dspy.Prediction,
    trace=None,
    pred_name=None,
    pred_trace=None,
) -> dspy.Prediction:

    logging.info(f"Example: {example}")
    logging.info(f"Prediction: {prediction}")

    correct_answer = example["answer"]
    correct_reasoning = example["reasoning"]
    generated_answer = prediction.get("answer")
    generated_reasoning = prediction.get("reasoning")

    similarity = f"Correct answer: {correct_answer} \nAnswer generated by the AI system: {generated_answer}. \nIs the correct answer similar to the answer generated by the AI system?"
    similarity_score = judge(question=similarity).get("answer")

    reasoning = f"Correct reasoning: {correct_reasoning} \nReasoning of the AI system: {generated_reasoning}. \nIs the reasoning of the AI system any similar to the correct reasoning?"
    reasoning_score = judge(question=similarity_score).get("answer")

    score = similarity_score + reasoning_score
    logging.info(f"Score: {score}")

    feedback = ""
    final_score = 0
    if score >= 1:
        final_score = 1
        feedback += f"Your answer or reasoning is acceptable. The correct answer is '{correct_answer}'."
    else:
        feedback += f"Sorry, neither your answer nor reasoning is acceptable. The correct answer is '{correct_answer}'."

    if correct_reasoning:
        feedback += f" Here's the full step-by-step reasoning:\n{correct_reasoning}\n\nThink about what takeaways you can learn from this solution to improve your future answers and approach to similar queries."

    return dspy.Prediction(score=final_score, feedback=feedback)


agent = GNAgent(
    corpus_path=CORPUS_PATH,
    pcorpus_path=PCORPUS_PATH,
    db_path=DB_PATH,
    naturalize_prompt=naturalize_prompt,
    rephrase_prompt=rephrase_prompt,
    analyze_prompt=analyze_prompt,
    check_prompt=check_prompt,
    summarize_prompt=summarize_prompt,
    synthesize_prompt=synthesize_prompt,
    split_prompt=split_prompt,
    finalize_prompt=finalize_prompt,
    sup_prompt1=sup_prompt1,
    sup_prompt2=sup_prompt2,
    plan_prompt=plan_prompt,
    refl_prompt=refl_prompt,
)


class GNAgentProgram(dspy.Module):
    """
    Transforms GNAgent to a dspy Program
    """

    def __init__(self, gn_agent: GNAgent):
        super().__init__()
        self.gn_agent = gn_agent
        self.executor = ThreadPoolExecutor(max_workers=1)

    def _run_handler(self, query):
        # Runs async handler in clean event loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(self.gn_agent.handler(query))
        finally:
            loop.close()

    def forward(self, query):
        # Runs async call in thread
        answer, reasoning = self.executor.submit(self._run_handler, query).result()
        return dspy.Prediction(
            answer=str(answer).strip(), reasoning=str(reasoning).strip()
        )


program = GNAgentProgram(agent)
