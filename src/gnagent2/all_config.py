"""
This module defines constructs for the optimizer.
See optimize.py
"""

import asyncio
import os
import random
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Literal

import dspy
import pandas as pd
from gnagent.agent import GNAgent
from gnagent.config import *
from gnagent.prompts import *
from langchain_core.messages import BaseMessage

EXAMPLE_PATH = "examples/examples.csv"


def get_dataset(split_ratio: int = 0.7, example_path: str = EXAMPLE_PATH) -> Any:
    data = pd.read_csv(example_path, nrows=30)
    data_dict = data_dicts = data[["query", "answer", "reasoning"]].to_dict(
        orient="records"
    )
    formatted = [
        dspy.Example(
            {"query": x["query"], "answer": x["answer"], "reasoning": x["reasoning"]}
        ).with_inputs("query")
        for x in data_dicts
    ]
    random.Random(2025).shuffle(formatted)
    train_set = formatted[: int(split_ratio * len(formatted))]
    eval_set = formatted[int(split_ratio * len(formatted)) :]

    # Always use 50-50 for validation and test sets
    val_set = eval_set[: int(0.5 * len(eval_set))]
    test_set = eval_set[int(0.5 * len(eval_set)) :]

    return train_set, val_set, test_set


class Judge(dspy.Signature):
    question: str = dspy.InputField()
    answer: bool = dspy.OutputField()


judge = dspy.Predict(Judge)


def match_checker(
    example: dspy.Example,
    prediction: dspy.Prediction,
    trace=None,
    pred_name=None,
    pred_trace=None,
) -> int:

    logging.info(f"Example: {example}")
    logging.info(f"Prediction: {prediction}")

    query = example["query"]
    correct_answer = example["answer"]
    correct_reasoning = example["reasoning"]
    generated_answer = prediction.get("answer")
    generated_reasoning = prediction.get("reasoning")

    answer_similarity = f"Correct answer: {correct_answer} \nAnswer generated by the AI system: {generated_answer}. \nDoes the answer generated by the AI system contains the correct answer?"
    similarity_score1 = judge(question=answer_similarity).get("answer")

    reasoning_similarity = f"Correct reasoning: {correct_reasoning} \nReasoning of the AI system: {generated_reasoning}. \nIs the reasoning of the AI system any similar to the correct reasoning?"
    similarity_score2 = judge(question=reasoning_similarity).get("answer")

    reasoning_logic = f"Query: {query} \nCorrect reasoning: {correct_reasoning} \nReasoning of the AI system: {generated_answer}. \nRegardless of the reasoning of the system being in line with the correct reasoning or not, does it seem logical in addressing the query?"
    logic_score = judge(question=reasoning_logic).get("answer")

    use = f"Query: {query} \nAnswer of the AI system: {generated_answer}. \nDoes the answer of the system of any use in addressing the query?"
    use_score = judge(question=use).get("answer")

    inclusion = f"Correct answer: {correct_answer} \nReasoning of the AI system: {generated_reasoning}. \nDoes the correct answer appears in the reasoning of the AI system?"
    inclusion_score = judge(question=inclusion).get("answer")

    score = (
        similarity_score1
        + similarity_score2
        + inclusion_score
        + logic_score
        + use_score
    )
    logging.info(f"Score: {score}")

    return 1 if score >= 2 else 0


def match_checker_feedback(
    example: dspy.Example,
    prediction: dspy.Prediction,
    trace=None,
    pred_name=None,
    pred_trace=None,
) -> dspy.Prediction:

    logging.info(f"Example: {example}")
    logging.info(f"Prediction: {prediction}")

    query = example["query"]
    correct_answer = example["answer"]
    correct_reasoning = example["reasoning"]
    generated_answer = prediction.get("answer")
    generated_reasoning = prediction.get("reasoning")

    answer_similarity = f"Correct answer: {correct_answer} \nAnswer generated by the AI system: {generated_answer}. \nDoes the answer generated by the AI system contains the correct answer?"
    similarity_score1 = judge(question=answer_similarity).get("answer")

    reasoning_similarity = f"Correct reasoning: {correct_reasoning} \nReasoning of the AI system: {generated_reasoning}. \nIs the reasoning of the AI system any similar to the correct reasoning?"
    similarity_score2 = judge(question=reasoning_similarity).get("answer")

    reasoning_logic = f"Query: {query} \nCorrect reasoning: {correct_reasoning} \nReasoning of the AI system: {generated_answer}. \nRegardless of the reasoning of the system being in line with the correct reasoning or not, does it seem logical in addressing the query?"
    logic_score = judge(question=reasoning_logic).get("answer")

    use = f"Query: {query} \nAnswer of the AI system: {generated_answer}. \nDoes the answer of the system of any use in addressing the query?"
    use_score = judge(question=use).get("answer")

    inclusion = f"Correct answer: {correct_answer} \nReasoning of the AI system: {generated_reasoning}. \nDoes the correct answer appears in the reasoning of the AI system?"
    inclusion_score = judge(question=inclusion).get("answer")

    score = (
        similarity_score1
        + similarity_score2
        + inclusion_score
        + logic_score
        + use_score
    )
    logging.info(f"Score: {score}")

    feedback = ""
    final_score = 0
    if score >= 2:
        final_score = 1
        feedback += f"Your answer or reasoning is acceptable. The correct answer is '{correct_answer}'."
    else:
        feedback += f"Sorry, neither your answer nor reasoning is acceptable. The correct answer is '{correct_answer}'."

    if correct_reasoning:
        feedback += f" Here's the full step-by-step reasoning:\n{correct_reasoning}\n\nThink about what takeaways you can learn from this solution to improve your future answers and approach to similar queries."

    return dspy.Prediction(score=final_score, feedback=feedback)
