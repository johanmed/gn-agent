"""
This module defines constructs for the optimizer.
See optimize.py
"""

import asyncio
import os
import random
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Literal

import dspy
import pandas as pd
from gnagent.agent import GNAgent
from gnagent.config import *
from gnagent.prompts import *
from langchain_core.messages import BaseMessage

API_KEY = os.getenv("API_KEY")

REFLECTION_MODEL = GENERATIVE_MODEL


class Judge(dspy.Signature):
    question: str = dspy.InputField()
    answer: bool = dspy.OutputField()


judge = dspy.Predict(Judge)


def match_checker(
    example: dspy.Example,
    prediction: dspy.Prediction,
    trace=None,
    pred_name=None,
    pred_trace=None,
) -> int:

    logging.info(f"Example: {example}")
    logging.info(f"Prediction: {prediction}")

    query = example["query"]
    correct_answer = example["answer"]
    correct_reasoning = example["reasoning"]
    generated_answer = prediction.get("answer")

    answer_similarity = f"Correct answer: {correct_answer} \nAnswer generated by the AI system: {generated_answer}. \nDoes the answer generated by the AI system contains the correct answer?"
    similarity_score = judge(question=answer_similarity).get("answer")

    reasoning_logic = f"Query: {query} \nCorrect reasoning: {correct_reasoning} \nReasoning of the AI system: {generated_answer}. \nRegardless of the reasoning of the system being in line with the correct reasoning or not, does it seem logical in addressing the query?"
    logic_score = judge(question=reasoning_logic).get("answer")

    use = f"Query: {query} \nAnswer of the AI system: {generated_answer}. \nDoes the answer of the system of any use in addressing the query?"
    use_score = judge(question=use).get("answer")

    score = similarity_score + logic_score + use_score
    logging.info(f"Score: {score}")

    return 1 if score >= 1 else 0


def match_checker_feedback(
    example: dspy.Example,
    prediction: dspy.Prediction,
    trace=None,
    pred_name=None,
    pred_trace=None,
) -> dspy.Prediction:

    logging.info(f"Example: {example}")
    logging.info(f"Prediction: {prediction}")

    query = example["query"]
    correct_answer = example["prompt_output"]
    correct_reasoning = example["reasoning"]
    generated_answer = prediction.get("prompt_output")

    answer_similarity = f"Correct answer: {correct_answer} \nAnswer generated by the AI system: {generated_answer}. \nDoes the answer generated by the AI system contains the correct answer?"
    similarity_score = judge(question=answer_similarity).get("answer")

    reasoning_logic = f"Query: {query} \nCorrect reasoning: {correct_reasoning} \nReasoning of the AI system: {generated_answer}. \nRegardless of the reasoning of the system being in line with the correct reasoning or not, does it seem logical in addressing the query?"
    logic_score = judge(question=reasoning_logic).get("answer")

    use = f"Query: {query} \nAnswer of the AI system: {generated_answer}. \nDoes the answer of the system of any use in addressing the query?"
    use_score = judge(question=use).get("answer")

    score = similarity_score + logic_score + use_score
    logging.info(f"Score: {score}")

    feedback = ""
    final_score = 0
    if score >= 2:
        final_score = 1
        feedback += f"Your answer or reasoning is acceptable. The correct answer is '{correct_answer}'."
    else:
        feedback += f"Sorry, neither your answer nor reasoning is acceptable. The correct answer is '{correct_answer}'."

    if correct_reasoning:
        feedback += f" Here's the full step-by-step reasoning:\n{correct_reasoning}\n\nThink about what takeaways you can learn from this solution to improve your future answers and approach to similar queries."

    return dspy.Prediction(score=final_score, feedback=feedback)
